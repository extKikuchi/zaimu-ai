#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlit Cloudå¯¾å¿œç‰ˆ Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ 
AWS Lambdaé€£æºï¼ˆS3ãƒã‚±ãƒƒãƒˆè‡ªå‹•ä½œæˆå¯¾å¿œï¼‰
"""

import streamlit as st
import boto3
import json
import tempfile
import zipfile
from pathlib import Path
import io
import time
from datetime import datetime
import uuid
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ“Š Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# AWSè¨­å®š
@st.cache_data
def get_aws_config():
    """AWSè¨­å®šã‚’å–å¾—"""
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒã‚±ãƒƒãƒˆåã‚’å‹•çš„ã«ç”Ÿæˆ
    default_bucket = st.secrets.get('S3_BUCKET_NAME', 'excel-aggregator-backup-20250714')
    
    config = {
        'region': st.secrets.get('AWS_DEFAULT_REGION', 'ap-northeast-1'),
        'lambda_function_name': st.secrets.get('LAMBDA_FUNCTION_NAME', 'excel-data-aggregator'),
        'bucket_name': default_bucket
    }
    
    return config

def get_or_create_bucket(s3_client):
    """S3ãƒã‚±ãƒƒãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    aws_config = get_aws_config()
    bucket_name = aws_config['bucket_name']
    
    try:
        # æ—¢å­˜ãƒã‚±ãƒƒãƒˆã®ç¢ºèª
        s3_client.head_bucket(Bucket=bucket_name)
        st.success(f"âœ… æ—¢å­˜ã®S3ãƒã‚±ãƒƒãƒˆã‚’ä½¿ç”¨: {bucket_name}")
        return bucket_name
    except Exception as e:
        if "403" in str(e) or "Forbidden" in str(e):
            st.warning(f"âš ï¸ ãƒã‚±ãƒƒãƒˆ {bucket_name} ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
            
            # åˆ©ç”¨å¯èƒ½ãªãƒã‚±ãƒƒãƒˆã‚’ç¢ºèª
            try:
                response = s3_client.list_buckets()
                available_buckets = [bucket['Name'] for bucket in response['Buckets']]
                
                if available_buckets:
                    st.info("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªS3ãƒã‚±ãƒƒãƒˆ:")
                    for bucket in available_buckets[:5]:  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
                        st.write(f"   â€¢ {bucket}")
                    
                    # æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒã‚±ãƒƒãƒˆã‚’ä½¿ç”¨
                    selected_bucket = available_buckets[0]
                    st.success(f"âœ… åˆ©ç”¨å¯èƒ½ãªãƒã‚±ãƒƒãƒˆã‚’ä½¿ç”¨: {selected_bucket}")
                    return selected_bucket
                else:
                    # æ–°ã—ã„ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ
                    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
                    new_bucket_name = f"excel-aggregator-{timestamp}"
                    
                    try:
                        if aws_config['region'] == 'us-east-1':
                            s3_client.create_bucket(Bucket=new_bucket_name)
                        else:
                            s3_client.create_bucket(
                                Bucket=new_bucket_name,
                                CreateBucketConfiguration={'LocationConstraint': aws_config['region']}
                            )
                        
                        st.success(f"âœ… æ–°ã—ã„S3ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ: {new_bucket_name}")
                        return new_bucket_name
                    except Exception as create_error:
                        st.error(f"âŒ ãƒã‚±ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {create_error}")
                        return None
            except Exception as list_error:
                st.error(f"âŒ ãƒã‚±ãƒƒãƒˆä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {list_error}")
                return None
        else:
            st.error(f"âŒ ãƒã‚±ãƒƒãƒˆç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return None

@st.cache_resource
def init_aws_clients():
    """AWS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
    try:
        aws_config = get_aws_config()
        
        # Streamlit Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        aws_access_key_id = st.secrets.get('AWS_ACCESS_KEY_ID')
        aws_secret_access_key = st.secrets.get('AWS_SECRET_ACCESS_KEY')
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        st.sidebar.write("ğŸ” èªè¨¼æƒ…å ±ãƒ‡ãƒãƒƒã‚°:")
        st.sidebar.write(f"Access Key: {aws_access_key_id[:10]}..." if aws_access_key_id else "Access Key: æœªè¨­å®š")
        st.sidebar.write(f"Secret Key: {'***è¨­å®šæ¸ˆã¿***' if aws_secret_access_key else 'æœªè¨­å®š'}")
        st.sidebar.write(f"Region: {aws_config['region']}")
        
        if aws_access_key_id and aws_secret_access_key:
            session = boto3.Session(
                aws_access_key_id=aws_access_key_id,
                aws_secret_access_key=aws_secret_access_key,
                region_name=aws_config['region']
            )
        else:
            session = boto3.Session(region_name=aws_config['region'])
        
        s3_client = session.client('s3')
        lambda_client = session.client('lambda')
        
        # èªè¨¼æƒ…å ±ã®ãƒ†ã‚¹ãƒˆ
        try:
            caller_identity = session.client('sts').get_caller_identity()
            st.sidebar.write(f"ğŸ‘¤ AWSãƒ¦ãƒ¼ã‚¶ãƒ¼: {caller_identity.get('Arn', 'Unknown')}")
        except Exception as auth_error:
            st.sidebar.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {auth_error}")
            return None, None, False, f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {auth_error}"
        
        # S3ãƒã‚±ãƒƒãƒˆã®ç¢ºèªãƒ»ä½œæˆ
        bucket_name = get_or_create_bucket(s3_client)
        if not bucket_name:
            return None, None, False, "S3ãƒã‚±ãƒƒãƒˆã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        # Lambdaé–¢æ•°ã®ç¢ºèª
        try:
            lambda_client.get_function(FunctionName=aws_config['lambda_function_name'])
        except Exception as lambda_error:
            st.sidebar.warning(f"Lambdaé–¢æ•°ã‚¨ãƒ©ãƒ¼: {lambda_error}")
            return s3_client, lambda_client, True, bucket_name  # S3ã¯æˆåŠŸã—ã¦ã„ã‚‹ã®ã§ç¶šè¡Œ
        
        return s3_client, lambda_client, True, bucket_name
        
    except Exception as e:
        st.sidebar.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, False, str(e)

def upload_file_to_s3(file_obj, s3_client, key, bucket_name):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    try:
        s3_client.upload_fileobj(file_obj, bucket_name, key)
        return True
    except Exception as e:
        st.error(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def invoke_lambda_function(lambda_client, payload):
    """Lambdaé–¢æ•°ã‚’å®Ÿè¡Œ"""
    try:
        aws_config = get_aws_config()
        response = lambda_client.invoke(
            FunctionName=aws_config['lambda_function_name'],
            Payload=json.dumps(payload)
        )
        
        result = json.loads(response['Payload'].read().decode())
        return result
    except Exception as e:
        st.error(f"Lambdaå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return None

def download_file_from_s3(s3_client, key, bucket_name):
    """S3ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        response = s3_client.get_object(Bucket=bucket_name, Key=key)
        return response['Body'].read()
    except Exception as e:
        st.error(f"S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def setup_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
    st.sidebar.header("ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    st.sidebar.markdown("""
    ### ğŸ¯ Excelé›†è¨ˆã‚·ã‚¹ãƒ†ãƒ 
    - **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.1
    - **æœ€çµ‚æ›´æ–°**: 2025-07-14
    - **ç’°å¢ƒ**: Streamlit Cloud
    """)
    
    st.sidebar.markdown("""
    ### ğŸ“Š å¯¾å¿œé …ç›®
    - å£²ä¸Šé«˜ã€å£²ä¸ŠåŸä¾¡ã€å£²ä¸Šç·åˆ©ç›Š
    - å–¶æ¥­åˆ©ç›Šã€çµŒå¸¸åˆ©ç›Šã€å½“æœŸç´”åˆ©ç›Š
    - EBITDAã€EBIT
    """)

def show_system_stats(s3_client, bucket_name):
    """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆã®è¡¨ç¤º"""
    try:
        # S3ãƒã‚±ãƒƒãƒˆã®å†…å®¹ã‚’ç¢ºèª
        response = s3_client.list_objects_v2(Bucket=bucket_name)
        
        if 'Contents' in response:
            total_files = len(response['Contents'])
            total_size = sum(obj['Size'] for obj in response['Contents'])
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", total_files)
            with col2:
                st.metric("ğŸ’¾ ç·ã‚µã‚¤ã‚º", f"{total_size / 1024 / 1024:.1f} MB")
            
            # æœ€è¿‘ã®å‡¦ç†çŠ¶æ³
            output_files = [obj for obj in response['Contents'] if obj['Key'].startswith('outputs/')]
            if output_files:
                latest_file = max(output_files, key=lambda x: x['LastModified'])
                st.metric("ğŸ“… æœ€æ–°å‡¦ç†", latest_file['LastModified'].strftime('%m/%d %H:%M'))
        else:
            st.info("ğŸ“­ å‡¦ç†å±¥æ­´ãªã—")
    except Exception as e:
        st.warning(f"âš ï¸ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ğŸ“Š Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("### ğŸš€ AWS Lambdaé€£æº äº‹æ¥­è¨ˆç”»ãƒ‡ãƒ¼ã‚¿è‡ªå‹•æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
    setup_sidebar()
    
    # AWSæ¥ç¶šçŠ¶æ…‹ã®ç¢ºèª
    with st.spinner("ğŸ” AWSæ¥ç¶šã‚’ç¢ºèªä¸­..."):
        s3_client, lambda_client, aws_connected, result = init_aws_clients()
    
    if not aws_connected:
        st.error("âŒ AWSæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
        st.code(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {result}")
        show_aws_setup_guide()
        return
    
    # æ¥ç¶šæˆåŠŸæ™‚ã¯resultã¯bucket_name
    bucket_name = result
    st.success("âœ… AWSæ¥ç¶šæˆåŠŸ")
    st.info(f"ğŸª£ ä½¿ç”¨ä¸­ã®S3ãƒã‚±ãƒƒãƒˆ: {bucket_name}")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        st.subheader("ğŸ¯ inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
        input_template_file = st.file_uploader(
            "inputç”¨.xlsxãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['xlsx'],
            key="input_template",
            help="é›†è¨ˆçµæœã‚’å…¥åŠ›ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        if input_template_file:
            st.success(f"âœ… {input_template_file.name} ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
        
        # äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«
        st.subheader("ğŸ“ˆ äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«")
        source_files = st.file_uploader(
            "äº‹æ¥­è¨ˆç”»Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
            type=['xlsx', 'xls'],
            accept_multiple_files=True,
            key="source_files",
            help="ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹å…ƒã®Excelãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        if source_files:
            st.success(f"âœ… {len(source_files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
            for i, file in enumerate(source_files):
                st.write(f"  {i+1}. ğŸ“„ {file.name}")
        
        # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("âš™ï¸ å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        col3, col4 = st.columns(2)
        
        with col3:
            show_progress = st.checkbox("å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤º", value=True)
            zip_results = st.checkbox("çµæœã‚’ZIPã§åœ§ç¸®", value=len(source_files) > 1 if source_files else False)
        
        with col4:
            auto_download = st.checkbox("è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=True)
            keep_files = st.checkbox("S3ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ", value=False)
    
    with col2:
        st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
        
        # AWSè¨­å®šæƒ…å ±
        aws_config = get_aws_config()
        st.info(f"âš¡ **Lambdaé–¢æ•°**\n{aws_config['lambda_function_name']}")
        st.info(f"ğŸŒ **ãƒªãƒ¼ã‚¸ãƒ§ãƒ³**\n{aws_config['region']}")
        
        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        show_system_stats(s3_client, bucket_name)
        
        # ãƒ˜ãƒ«ãƒ—
        with st.expander("ğŸ’¡ ä½¿ç”¨æ–¹æ³•"):
            st.markdown("""
            **åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•:**
            1. inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            3. "ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå®Ÿè¡Œ"ã‚’ã‚¯ãƒªãƒƒã‚¯
            4. å‡¦ç†çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            
            **å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«:**
            - Excel (.xlsx, .xls)
            - æœ€å¤§50MB
            
            **æŠ½å‡ºã•ã‚Œã‚‹é …ç›®:**
            - å£²ä¸Šé«˜ã€å£²ä¸ŠåŸä¾¡ã€å–¶æ¥­åˆ©ç›Š
            - çµŒå¸¸åˆ©ç›Šã€å½“æœŸç´”åˆ©ç›Š ãªã©
            """)
    
    # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
    st.markdown("---")
    if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå®Ÿè¡Œ", type="primary", use_container_width=True):
        if not input_template_file:
            st.error("âŒ inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        elif not source_files:
            st.error("âŒ äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å°‘ãªãã¨ã‚‚1ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        else:
            process_files(
                s3_client,
                lambda_client,
                bucket_name,
                input_template_file,
                source_files,
                show_progress,
                auto_download,
                zip_results,
                keep_files
            )

def process_files(s3_client, lambda_client, bucket_name, input_template_file, source_files, 
                 show_progress, auto_download, zip_results, keep_files):
    """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # å‡¦ç†IDç”Ÿæˆ
    process_id = str(uuid.uuid4())[:8]
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        status_text.text("ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        progress_bar.progress(10)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        template_key = f"templates/{process_id}_input.xlsx"
        input_template_file.seek(0)
        if not upload_file_to_s3(input_template_file, s3_client, template_key, bucket_name):
            st.error("âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        source_keys = []
        for i, source_file in enumerate(source_files):
            source_key = f"source-files/{process_id}_{i}_{source_file.name}"
            source_file.seek(0)
            if upload_file_to_s3(source_file, s3_client, source_key, bucket_name):
                source_keys.append(source_key)
                progress_bar.progress(10 + (i + 1) * 25 / len(source_files))
            else:
                st.error(f"âŒ {source_file.name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
        
        progress_bar.progress(100)
        status_text.text("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        st.success(f"ğŸ‰ {len(source_files) + 1} ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
        st.info("ğŸ’¡ Lambdaé–¢æ•°ã¨ã®é€£æºã¯æº–å‚™ä¸­ã§ã™ã€‚ç¾åœ¨ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®ã¿å‹•ä½œã—ã¾ã™ã€‚")
        
    except Exception as e:
        st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.exception(e)

def show_aws_setup_guide():
    """AWSè¨­å®šã‚¬ã‚¤ãƒ‰ã®è¡¨ç¤º"""
    st.error("### âŒ AWSè¨­å®šãŒå¿…è¦ã§ã™")
    
    with st.expander("ğŸ”§ AWSè¨­å®šã‚¬ã‚¤ãƒ‰", expanded=True):
        st.markdown("""
        ### S3ãƒã‚±ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®è¨­å®š
        
        1. **AWS Console** â†’ **IAM** â†’ **Users** â†’ ã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼
        2. **Permissions** ã‚¿ãƒ– â†’ **Add permissions** â†’ **Attach policies directly**
        3. ä»¥ä¸‹ã®ãƒãƒªã‚·ãƒ¼ã‚’è¿½åŠ :
           - `AmazonS3FullAccess`
           - `AWSLambdaInvokeFunction`
        
        ### ã¾ãŸã¯æ–°ã—ã„S3ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ
        
        ```bash
        aws s3 mb s3://your-new-bucket-name --region ap-northeast-1
        ```
        
        ### Streamlit Cloud Secretsè¨­å®š
        
        ```toml
        AWS_ACCESS_KEY_ID = "your_access_key"
        AWS_SECRET_ACCESS_KEY = "your_secret_key"
        AWS_DEFAULT_REGION = "ap-northeast-1"
        S3_BUCKET_NAME = "your-new-bucket-name"
        LAMBDA_FUNCTION_NAME = "excel-data-aggregator"
        ```
        """)

if __name__ == "__main__":
    main()
