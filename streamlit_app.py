#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlit Cloudå¯¾å¿œç‰ˆ Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ 
AWS Lambdaé€£æºï¼ˆsmart_aggregatorä¾å­˜ãªã—ï¼‰
"""

import streamlit as st
import pandas as pd
import boto3
import json
import tempfile
import zipfile
from pathlib import Path
import io
import time
from datetime import datetime
import uuid
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ“Š Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# AWSè¨­å®š
@st.cache_data
def get_aws_config():
    """AWSè¨­å®šã‚’å–å¾—"""
    return {
        'region': st.secrets.get('AWS_DEFAULT_REGION', 'ap-northeast-1'),
        'lambda_function_name': st.secrets.get('LAMBDA_FUNCTION_NAME', 'excel-data-aggregator'),
        'bucket_name': st.secrets.get('S3_BUCKET_NAME', 'excel-aggregator-20250714-095126')
    }

@st.cache_resource
def init_aws_clients():
    """AWS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
    try:
        aws_config = get_aws_config()
        
        # Streamlit Cloudã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        aws_access_key_id = st.secrets.get('AWS_ACCESS_KEY_ID')
        aws_secret_access_key = st.secrets.get('AWS_SECRET_ACCESS_KEY')
        
        if aws_access_key_id and aws_secret_access_key:
            session = boto3.Session(
                aws_access_key_id=aws_access_key_id,
                aws_secret_access_key=aws_secret_access_key,
                region_name=aws_config['region']
            )
        else:
            session = boto3.Session(region_name=aws_config['region'])
        
        s3_client = session.client('s3')
        lambda_client = session.client('lambda')
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        s3_client.head_bucket(Bucket=aws_config['bucket_name'])
        lambda_client.get_function(FunctionName=aws_config['lambda_function_name'])
        
        return s3_client, lambda_client, True, None
    except Exception as e:
        return None, None, False, str(e)

def upload_file_to_s3(file_obj, s3_client, key):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    try:
        aws_config = get_aws_config()
        s3_client.upload_fileobj(file_obj, aws_config['bucket_name'], key)
        return True
    except Exception as e:
        st.error(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def invoke_lambda_function(lambda_client, payload):
    """Lambdaé–¢æ•°ã‚’å®Ÿè¡Œ"""
    try:
        aws_config = get_aws_config()
        response = lambda_client.invoke(
            FunctionName=aws_config['lambda_function_name'],
            Payload=json.dumps(payload)
        )
        
        result = json.loads(response['Payload'].read().decode())
        return result
    except Exception as e:
        st.error(f"Lambdaå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return None

def download_file_from_s3(s3_client, key):
    """S3ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        aws_config = get_aws_config()
        response = s3_client.get_object(Bucket=aws_config['bucket_name'], Key=key)
        return response['Body'].read()
    except Exception as e:
        st.error(f"S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def setup_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
    st.sidebar.header("ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    st.sidebar.markdown("""
    ### ğŸ¯ Excelé›†è¨ˆã‚·ã‚¹ãƒ†ãƒ 
    - **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0
    - **æœ€çµ‚æ›´æ–°**: 2025-07-14
    - **ç’°å¢ƒ**: Streamlit Cloud
    """)
    
    st.sidebar.markdown("""
    ### ğŸ“Š å¯¾å¿œé …ç›®
    - å£²ä¸Šé«˜
    - å£²ä¸ŠåŸä¾¡  
    - å£²ä¸Šç·åˆ©ç›Š
    - å–¶æ¥­åˆ©ç›Š
    - çµŒå¸¸åˆ©ç›Š
    - å½“æœŸç´”åˆ©ç›Š
    - EBITDA
    - EBIT
    """)
    
    st.sidebar.markdown("""
    ### ğŸ’¡ ãƒ˜ãƒ«ãƒ—
    - æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 50MB
    - å¯¾å¿œå½¢å¼: .xlsx, .xls
    - è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«åŒæ™‚å‡¦ç†å¯¾å¿œ
    """)

def show_system_stats(s3_client):
    """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆã®è¡¨ç¤º"""
    try:
        aws_config = get_aws_config()
        
        # S3ãƒã‚±ãƒƒãƒˆã®å†…å®¹ã‚’ç¢ºèª
        response = s3_client.list_objects_v2(Bucket=aws_config['bucket_name'])
        
        if 'Contents' in response:
            total_files = len(response['Contents'])
            total_size = sum(obj['Size'] for obj in response['Contents'])
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", total_files)
            with col2:
                st.metric("ğŸ’¾ ç·ã‚µã‚¤ã‚º", f"{total_size / 1024 / 1024:.1f} MB")
            
            # æœ€è¿‘ã®å‡¦ç†çŠ¶æ³
            output_files = [obj for obj in response['Contents'] if obj['Key'].startswith('outputs/')]
            if output_files:
                latest_file = max(output_files, key=lambda x: x['LastModified'])
                st.metric("ğŸ“… æœ€æ–°å‡¦ç†", latest_file['LastModified'].strftime('%m/%d %H:%M'))
        else:
            st.info("ğŸ“­ å‡¦ç†å±¥æ­´ãªã—")
    except Exception as e:
        st.warning(f"âš ï¸ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def download_files(s3_client, processed_files, zip_results):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†"""
    
    if len(processed_files) == 1:
        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        file_key = processed_files[0]
        file_data = download_file_from_s3(s3_client, file_key)
        
        if file_data:
            file_name = Path(file_key).name
            st.download_button(
                label=f"ğŸ“„ {file_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=file_data,
                file_name=file_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    
    elif zip_results:
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§åœ§ç¸®
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for file_key in processed_files:
                file_data = download_file_from_s3(s3_client, file_key)
                if file_data:
                    file_name = Path(file_key).name
                    zip_file.writestr(file_name, file_data)
        
        zip_buffer.seek(0)
        
        st.download_button(
            label=f"ğŸ“¦ å…¨çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({len(processed_files)}ä»¶)",
            data=zip_buffer.getvalue(),
            file_name=f"excel_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip"
        )
    
    else:
        # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        for i, file_key in enumerate(processed_files):
            file_data = download_file_from_s3(s3_client, file_key)
            if file_data:
                file_name = Path(file_key).name
                st.download_button(
                    label=f"ğŸ“„ {file_name}",
                    data=file_data,
                    file_name=file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=f"download_{i}"
                )

def cleanup_files(s3_client, template_key, source_keys):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    try:
        aws_config = get_aws_config()
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        keys_to_delete = [template_key] + source_keys
        
        for key in keys_to_delete:
            s3_client.delete_object(Bucket=aws_config['bucket_name'], Key=key)
        
        st.info(f"ğŸ§¹ {len(keys_to_delete)} å€‹ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")
    except Exception as e:
        st.warning(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

def process_files(s3_client, lambda_client, input_template_file, source_files, 
                 show_progress, auto_download, zip_results, keep_files):
    """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # å‡¦ç†IDç”Ÿæˆ
    process_id = str(uuid.uuid4())[:8]
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        status_text.text("ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        progress_bar.progress(10)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        template_key = f"templates/{process_id}_input.xlsx"
        input_template_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
        if not upload_file_to_s3(input_template_file, s3_client, template_key):
            st.error("âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        source_keys = []
        for i, source_file in enumerate(source_files):
            source_key = f"source-files/{process_id}_{i}_{source_file.name}"
            source_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
            if upload_file_to_s3(source_file, s3_client, source_key):
                source_keys.append(source_key)
                progress_bar.progress(10 + (i + 1) * 25 / len(source_files))
            else:
                st.error(f"âŒ {source_file.name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: Lambdaé–¢æ•°ã‚’å®Ÿè¡Œ
        status_text.text("âš¡ Lambdaé–¢æ•°ã‚’å®Ÿè¡Œä¸­...")
        progress_bar.progress(40)
        
        aws_config = get_aws_config()
        
        # Lambdaå®Ÿè¡Œç”¨ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
        payload = {
            "bucket": aws_config['bucket_name'],
            "input_template_key": template_key,
            "source_files": source_keys,
            "output_prefix": f"outputs/{process_id}_"
        }
        
        if show_progress:
            with st.expander("ğŸ” å®Ÿè¡Œè©³ç´°"):
                st.json(payload)
        
        # Lambdaé–¢æ•°å®Ÿè¡Œ
        lambda_result = invoke_lambda_function(lambda_client, payload)
        
        if not lambda_result:
            st.error("âŒ Lambdaé–¢æ•°ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        progress_bar.progress(60)
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: çµæœã®å‡¦ç†
        status_text.text("ğŸ“Š çµæœã‚’å‡¦ç†ä¸­...")
        
        if lambda_result.get('statusCode') == 200:
            body = json.loads(lambda_result['body'])
            results = body.get('results', [])
            processed_files = body.get('processed_files', [])
            
            progress_bar.progress(80)
            
            # çµæœè¡¨ç¤º
            st.header("ğŸ“‹ å‡¦ç†çµæœ")
            
            # çµæœãƒ†ãƒ¼ãƒ–ãƒ«
            if results:
                results_df = pd.DataFrame(results)
                st.dataframe(results_df, use_container_width=True)
                
                # æˆåŠŸ/å¤±æ•—ã®çµ±è¨ˆ
                success_count = len([r for r in results if r['status'] == 'success'])
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("âœ… æˆåŠŸ", success_count)
                with col2:
                    st.metric("âŒ å¤±æ•—", len(results) - success_count)
                with col3:
                    st.metric("ğŸ“Š ç·æŠ½å‡ºé …ç›®", sum(r.get('extracted_items', 0) for r in results))
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            if processed_files:
                status_text.text("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™ä¸­...")
                progress_bar.progress(90)
                
                st.header("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                
                download_files(s3_client, processed_files, zip_results)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if not keep_files:
                    cleanup_files(s3_client, template_key, source_keys)
            
            progress_bar.progress(100)
            status_text.text("âœ… å‡¦ç†å®Œäº†")
            
            st.success(f"ğŸ‰ å‡¦ç†å®Œäº†: {len(processed_files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ")
            st.balloons()
        else:
            st.error(f"âŒ Lambdaå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {lambda_result}")
            
    except Exception as e:
        st.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.exception(e)

def show_aws_setup_guide():
    """AWSè¨­å®šã‚¬ã‚¤ãƒ‰ã®è¡¨ç¤º"""
    st.error("### âŒ AWSè¨­å®šãŒå¿…è¦ã§ã™")
    
    with st.expander("ğŸ”§ AWSè¨­å®šã‚¬ã‚¤ãƒ‰", expanded=True):
        st.markdown("""
        ### Streamlit Cloud ã§ã®AWSè¨­å®šæ‰‹é †
        
        1. **Streamlit Cloud ã‚¢ãƒ—ãƒªã®è¨­å®šç”»é¢**ã«ã‚¢ã‚¯ã‚»ã‚¹
        2. **âš™ï¸ Settings** â†’ **ğŸ” Secrets** ã‚¿ãƒ–ã‚’é¸æŠ
        3. ä»¥ä¸‹ã®å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ **Save** ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼š
        
        ```toml
        AWS_ACCESS_KEY_ID = "your_access_key_id"
        AWS_SECRET_ACCESS_KEY = "your_secret_access_key"
        AWS_DEFAULT_REGION = "ap-northeast-1"
        S3_BUCKET_NAME = "excel-aggregator-20250714-095126"
        LAMBDA_FUNCTION_NAME = "excel-data-aggregator"
        ```
        
        ### âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …
        - AWSèªè¨¼æƒ…å ±ã¯**çµ¶å¯¾ã«**GitHubãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã—ãªã„ã§ãã ã•ã„
        - Streamlit Cloudã®Secretsã¯æš—å·åŒ–ã•ã‚Œã¦å®‰å…¨ã«ä¿å­˜ã•ã‚Œã¾ã™
        - è¨­å®šå¾Œã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„
        
        ### ğŸ”‘ å¿…è¦ãª AWS æ¨©é™
        - **S3**: GetObject, PutObject, DeleteObject, ListBucket
        - **Lambda**: InvokeFunction
        """)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ğŸ“Š Excel ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("### ğŸš€ AWS Lambdaé€£æº äº‹æ¥­è¨ˆç”»ãƒ‡ãƒ¼ã‚¿è‡ªå‹•æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼æƒ…å ±
    setup_sidebar()
    
    # AWSæ¥ç¶šçŠ¶æ…‹ã®ç¢ºèª
    with st.spinner("ğŸ” AWSæ¥ç¶šã‚’ç¢ºèªä¸­..."):
        s3_client, lambda_client, aws_connected, error_message = init_aws_clients()
    
    if not aws_connected:
        st.error("âŒ AWSæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
        if error_message:
            st.code(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_message}")
        show_aws_setup_guide()
        return
    
    st.success("âœ… AWSæ¥ç¶šæˆåŠŸ")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        st.subheader("ğŸ¯ inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
        input_template_file = st.file_uploader(
            "inputç”¨.xlsxãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=['xlsx'],
            key="input_template",
            help="é›†è¨ˆçµæœã‚’å…¥åŠ›ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        if input_template_file:
            st.success(f"âœ… {input_template_file.name} ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
        
        # äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«
        st.subheader("ğŸ“ˆ äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«")
        source_files = st.file_uploader(
            "äº‹æ¥­è¨ˆç”»Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
            type=['xlsx', 'xls'],
            accept_multiple_files=True,
            key="source_files",
            help="ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹å…ƒã®Excelãƒ•ã‚¡ã‚¤ãƒ«"
        )
        
        if source_files:
            st.success(f"âœ… {len(source_files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ")
            for i, file in enumerate(source_files):
                st.write(f"  {i+1}. ğŸ“„ {file.name}")
        
        # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("âš™ï¸ å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        col3, col4 = st.columns(2)
        
        with col3:
            show_progress = st.checkbox("å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤º", value=True)
            zip_results = st.checkbox("çµæœã‚’ZIPã§åœ§ç¸®", value=len(source_files) > 1 if source_files else False)
        
        with col4:
            auto_download = st.checkbox("è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=True)
            keep_files = st.checkbox("S3ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ", value=False)
    
    with col2:
        st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹")
        
        # AWSè¨­å®šæƒ…å ±
        aws_config = get_aws_config()
        st.info(f"ğŸª£ **S3ãƒã‚±ãƒƒãƒˆ**\n{aws_config['bucket_name']}")
        st.info(f"âš¡ **Lambdaé–¢æ•°**\n{aws_config['lambda_function_name']}")
        st.info(f"ğŸŒ **ãƒªãƒ¼ã‚¸ãƒ§ãƒ³**\n{aws_config['region']}")
        
        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        show_system_stats(s3_client)
        
        # ãƒ˜ãƒ«ãƒ—
        with st.expander("ğŸ’¡ ä½¿ç”¨æ–¹æ³•"):
            st.markdown("""
            **åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•:**
            1. inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            3. "ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå®Ÿè¡Œ"ã‚’ã‚¯ãƒªãƒƒã‚¯
            4. å‡¦ç†çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            
            **å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«:**
            - Excel (.xlsx, .xls)
            - æœ€å¤§50MB
            
            **æŠ½å‡ºã•ã‚Œã‚‹é …ç›®:**
            - å£²ä¸Šé«˜ã€å£²ä¸ŠåŸä¾¡ã€å–¶æ¥­åˆ©ç›Š
            - çµŒå¸¸åˆ©ç›Šã€å½“æœŸç´”åˆ©ç›Š ãªã©
            """)
    
    # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
    st.markdown("---")
    if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå®Ÿè¡Œ", type="primary", use_container_width=True):
        if not input_template_file:
            st.error("âŒ inputç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        elif not source_files:
            st.error("âŒ äº‹æ¥­è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å°‘ãªãã¨ã‚‚1ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        else:
            process_files(
                s3_client,
                lambda_client,
                input_template_file,
                source_files,
                show_progress,
                auto_download,
                zip_results,
                keep_files
            )

if __name__ == "__main__":
    main()
